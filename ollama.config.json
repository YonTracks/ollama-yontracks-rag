{
  "version": "1.0",
  "globalSettings": {
    "apiEndpoint": "http://localhost:11434",
    "defaultModel": "llama3.1",
    "timeout": 30000,
    "stream": true
  },
  "models": {
    "llama3.1": {
      "description": "LLaMA v3.1 - General purpose large language model",
      "settings": {
        "temperature": 0.7,
        "num_ctx": 2048,
        "stream": true
      }
    }
  }
}
